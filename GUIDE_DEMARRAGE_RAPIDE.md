# üöÄ GUIDE D√âMARRAGE RAPIDE - Action Imm√©diate

**Date** : 2026-01-18  
**Objectif** : D√©marrer l'int√©gration du moteur CEREDIS AUJOURD'HUI  
**Dur√©e estim√©e** : 8 heures

---

## ‚ö° ACTIONS IMM√âDIATES (Prochaines 30 minutes)

### √âtape 1 : Pr√©parer l'environnement (5 min)

```bash
# Se positionner dans le projet Next.js
cd /home/ceredis/chansons-francaises-app

# V√©rifier que l'app compile
npm run type-check

# S'assurer que Git est √† jour
git status
git pull origin main

# Cr√©er une nouvelle branche
git checkout -b feature/ceredis-engine-integration
```

### √âtape 2 : Extraire l'archive du moteur (5 min)

```bash
# Cr√©er un dossier temporaire pour l'extraction
mkdir -p /tmp/ceredis-engine-extraction

# Extraire l'archive
cd /tmp/ceredis-engine-extraction
tar -xzf /mnt/user-data/outputs/ceredis-engine-v1.0.tar.gz

# Examiner la structure
ls -la ceredis-engine/
ls -la ceredis-engine/src/engine/
ls -la ceredis-engine/config/

# Noter les fichiers disponibles :
# - evidenceAggregator.js
# - competencyCalculator.js
# - domainCalculator.js
# - ceredisCalculator.js
# - cecrlDecider.js
# - levelValidator.js
# - ceredis.v1.json (config)
```

### √âtape 3 : Cr√©er la structure dans Next.js (10 min)

```bash
# Retour au projet
cd /home/ceredis/chansons-francaises-app

# Cr√©er la structure du service
mkdir -p services/ceredis-calculator/engine
mkdir -p services/ceredis-calculator/__tests__

# Cr√©er les fichiers de base
touch services/ceredis-calculator/types.ts
touch services/ceredis-calculator/config.ts
touch services/ceredis-calculator/index.ts
touch services/ceredis-calculator/README.md

# Cr√©er les modules du moteur
touch services/ceredis-calculator/engine/evidenceAggregator.ts
touch services/ceredis-calculator/engine/competencyCalculator.ts
touch services/ceredis-calculator/engine/domainCalculator.ts
touch services/ceredis-calculator/engine/ceredisCalculator.ts
touch services/ceredis-calculator/engine/cecrlDecider.ts
touch services/ceredis-calculator/engine/levelValidator.ts

# Cr√©er l'API Route
mkdir -p app/api/ceredis/calculate
touch app/api/ceredis/calculate/route.ts

# Cr√©er le client frontend
mkdir -p lib/ceredis
touch lib/ceredis/client.ts
touch lib/ceredis/hooks.ts
touch lib/ceredis/types.ts

echo "‚úÖ Structure cr√©√©e avec succ√®s"
```

### √âtape 4 : Ouvrir les fichiers dans l'√©diteur (5 min)

```bash
# Ouvrir VS Code dans le projet
code .

# Ouvrir les fichiers cl√©s :
# - services/ceredis-calculator/types.ts
# - services/ceredis-calculator/config.ts
# - services/ceredis-calculator/engine/ceredisCalculator.ts
# - /tmp/ceredis-engine-extraction/ceredis-engine/config/ceredis.v1.json
```

### √âtape 5 : Pr√©parer les r√©f√©rences (5 min)

```bash
# Ouvrir le plan d'int√©gration
code /mnt/project/PLAN_INTEGRATION_MOTEUR_CEREDIS.md

# Avoir sous les yeux :
# 1. Le plan d'int√©gration (r√©f√©rence)
# 2. L'archive extraite (code source JS)
# 3. Le projet Next.js (destination)
```

---

## üìù CODE √Ä COPIER-COLLER (Prochaines 3 heures)

### Fichier 1 : `services/ceredis-calculator/types.ts` (30 min)

```typescript
/**
 * Types pour le moteur de calcul CEREDIS
 * 
 * Le moteur CEREDIS calcule :
 * - Un score global de 0 √† 600 points
 * - Un niveau CECRL (A2, B1, B2, C1)
 * - Des scores par domaine et par comp√©tence
 * 
 * Bas√© sur les preuves (Evidences) collect√©es via les activit√©s
 */

// ============================================================================
// TYPES DE BASE
// ============================================================================

/**
 * Types de preuves selon leur complexit√© cognitive
 * P1 : Reconnaissance/Identification (poids 0.15)
 * P2 : Compr√©hension/Application (poids 0.30)
 * P3 : Analyse/Synth√®se (poids 0.35)
 * P4 : √âvaluation/Cr√©ation (poids 0.20)
 */
export type EvidenceType = 'P1' | 'P2' | 'P3' | 'P4';

/**
 * IDs des 19 comp√©tences CEREDIS
 */
export type CompetencyId = 
  // D1: Compr√©hension de l'oral
  | '1.1' | '1.2' | '1.3'
  // D2: Compr√©hension de l'√©crit
  | '2.1' | '2.2' | '2.3'
  // D3: Production √©crite
  | '3.1' | '3.2' | '3.3'
  // D4: Interaction et interpr√©tation
  | '4.1' | '4.2' | '4.3'
  // D5: M√©talinguistique et m√©tacognitif
  | '5.1' | '5.2' | '5.3' | '5.4' | '5.5' | '5.6' | '5.7';

/**
 * IDs des 5 domaines CEREDIS
 */
export type DomainId = 'D1' | 'D2' | 'D3' | 'D4' | 'D5';

/**
 * Niveaux CECRL possibles
 */
export type CecrlLevel = 'A2' | 'B1' | 'B2' | 'C1';

// ============================================================================
// STRUCTURES DE DONN√âES
// ============================================================================

/**
 * Une preuve d'apprentissage (Evidence)
 * Cr√©√©e √† chaque compl√©tion d'activit√©
 */
export interface Evidence {
  /** ID unique de la preuve */
  id: string;
  
  /** ID de l'utilisateur */
  userId: string;
  
  /** ID de la comp√©tence valid√©e */
  competencyId: CompetencyId;
  
  /** Type de preuve (complexit√© cognitive) */
  type: EvidenceType;
  
  /** Score obtenu (0-100) */
  score: number;
  
  /** Date de cr√©ation */
  timestamp: string;
  
  /** M√©tadonn√©es optionnelles */
  metadata?: {
    activityId?: string;
    sessionId?: string;
    duration?: number;
    attempts?: number;
    [key: string]: any;
  };
}

/**
 * Score agr√©g√© pour une comp√©tence
 */
export interface CompetencyScore {
  /** Score final (0-100) */
  score: number;
  
  /** Nombre de preuves utilis√©es */
  evidenceCount: number;
  
  /** Types de preuves collect√©es */
  evidenceTypes: EvidenceType[];
  
  /** Score minimum (pour debug) */
  minScore?: number;
  
  /** Score maximum (pour debug) */
  maxScore?: number;
  
  /** Score moyen (pour debug) */
  avgScore?: number;
}

/**
 * R√©sultat du calcul CEREDIS complet
 */
export interface CeredisResult {
  /** ID de l'utilisateur */
  userId: string;
  
  /** Score CEREDIS global (0-600) */
  ceredisScore: number;
  
  /** Niveau CECRL attribu√© */
  cecrlLevel: CecrlLevel;
  
  /** Scores par domaine (0-100 chacun) */
  domainScores: Record<DomainId, number>;
  
  /** Scores d√©taill√©s par comp√©tence */
  competencyScores: Record<CompetencyId, CompetencyScore>;
  
  /** R√©sultat de validation */
  validation: ValidationResult;
  
  /** Date du calcul */
  computedAt: string;
  
  /** Version du moteur utilis√©e */
  engineVersion: string;
}

/**
 * R√©sultat de validation des r√®gles strictes
 */
export interface ValidationResult {
  /** Le niveau est-il valid√© ? */
  valid: boolean;
  
  /** Niveau final (peut √™tre d√©grad√©) */
  level: CecrlLevel;
  
  /** Niveau initial avant validation */
  initialLevel?: CecrlLevel;
  
  /** Erreurs bloquantes */
  errors: string[];
  
  /** Avertissements non-bloquants */
  warnings: string[];
  
  /** Raison de d√©gradation √©ventuelle */
  degradationReason?: string;
}

// ============================================================================
// CONFIGURATION
// ============================================================================

/**
 * Configuration du domaine
 */
export interface DomainConfig {
  /** Nom du domaine */
  name: string;
  
  /** Poids dans le calcul global (somme = 1.0) */
  weight: number;
  
  /** IDs des comp√©tences du domaine */
  competencies: CompetencyId[];
  
  /** Score minimum requis (optionnel) */
  minScore?: number;
}

/**
 * Exigences pour un niveau CECRL
 */
export interface LevelRequirements {
  /** Score CEREDIS minimum */
  minScore: number;
  
  /** Types de preuves obligatoires */
  requiredEvidenceTypes: EvidenceType[];
  
  /** Scores minimums par domaine (optionnel) */
  requiredDomains?: Record<DomainId, { minScore: number }>;
}

/**
 * Configuration compl√®te du moteur CEREDIS
 */
export interface CeredisConfig {
  /** Version de la configuration */
  version: string;
  
  /** √âchelle de notation (min-max) */
  scale: {
    min: number;
    max: number;
  };
  
  /** Poids des types de preuves */
  evidenceWeights: Record<EvidenceType, number>;
  
  /** Configuration des 5 domaines */
  domains: Record<DomainId, DomainConfig>;
  
  /** Seuils CECRL [min, max] */
  cecrlThresholds: Record<CecrlLevel, [number, number]>;
  
  /** Exigences par niveau */
  levels: Record<string, LevelRequirements>;
}

// ============================================================================
// TYPES INTERM√âDIAIRES (pour les calculs)
// ============================================================================

/**
 * Preuves agr√©g√©es par comp√©tence
 */
export interface AggregatedEvidences {
  [competencyId: string]: Evidence[];
}

/**
 * Statistiques de calcul (pour debug)
 */
export interface CalculationStats {
  totalEvidences: number;
  competenciesWithEvidences: number;
  domainsWithScores: number;
  averageScore: number;
  processingTime?: number;
}

// ============================================================================
// TYPES POUR L'API
// ============================================================================

/**
 * Requ√™te de calcul de score
 */
export interface CalculateScoreRequest {
  userId: string;
  includeDetails?: boolean;
  includeStats?: boolean;
}

/**
 * R√©ponse de l'API de calcul
 */
export interface CalculateScoreResponse {
  success: boolean;
  result?: CeredisResult;
  stats?: CalculationStats;
  error?: {
    code: string;
    message: string;
  };
}

// ============================================================================
// EXPORTS GROUP√âS
// ============================================================================

export type {
  // Types de base
  Evidence,
  CompetencyScore,
  CeredisResult,
  ValidationResult,
  
  // Configuration
  DomainConfig,
  LevelRequirements,
  CeredisConfig,
  
  // Interm√©diaires
  AggregatedEvidences,
  CalculationStats,
  
  // API
  CalculateScoreRequest,
  CalculateScoreResponse,
};
```

### Fichier 2 : `services/ceredis-calculator/config.ts` (20 min)

```typescript
import type { CeredisConfig, DomainId, CompetencyId } from './types';

/**
 * Configuration du moteur CEREDIS v1.0
 * 
 * Cette configuration d√©finit :
 * - L'√©chelle de notation (0-600)
 * - Les poids des types de preuves (P1-P4)
 * - Les 5 domaines et leurs comp√©tences
 * - Les seuils CECRL
 * - Les r√®gles de validation stricte
 */
export const CEREDIS_CONFIG: CeredisConfig = {
  version: "1.0",
  
  // √âchelle de notation globale
  scale: {
    min: 0,
    max: 600
  },
  
  // Poids des types de preuves
  // Somme = 1.00 (r√©partition selon complexit√© cognitive)
  evidenceWeights: {
    P1: 0.15, // Reconnaissance/Identification
    P2: 0.30, // Compr√©hension/Application
    P3: 0.35, // Analyse/Synth√®se
    P4: 0.20  // √âvaluation/Cr√©ation
  },

  // Configuration des 5 domaines
  domains: {
    D1: {
      name: "Compr√©hension de l'oral (chansons)",
      weight: 0.20,
      competencies: ['1.1', '1.2', '1.3']
    },
    D2: {
      name: "Compr√©hension de l'√©crit (paroles)",
      weight: 0.20,
      competencies: ['2.1', '2.2', '2.3']
    },
    D3: {
      name: "Production √©crite",
      weight: 0.20,
      competencies: ['3.1', '3.2', '3.3']
    },
    D4: {
      name: "Interaction et interpr√©tation",
      weight: 0.20,
      competencies: ['4.1', '4.2', '4.3']
    },
    D5: {
      name: "M√©talinguistique et m√©tacognitif",
      weight: 0.20,
      competencies: ['5.1', '5.2', '5.3', '5.4', '5.5', '5.6', '5.7'],
      minScore: 60 // Requis pour B2+
    }
  },

  // Seuils CECRL [score min, score max]
  cecrlThresholds: {
    A2: [200, 299],
    B1: [300, 399],
    B2: [400, 499],
    C1: [500, 599]
  },

  // Exigences strictes par niveau
  levels: {
    B2: {
      minScore: 400,
      requiredEvidenceTypes: ['P3'], // Doit avoir au moins une P3
      requiredDomains: {
        D5: { minScore: 60 } // Domaine 5 ‚â• 60
      }
    },
    C1: {
      minScore: 500,
      requiredEvidenceTypes: ['P3', 'P4'], // Doit avoir P3 ET P4
      requiredDomains: {
        D5: { minScore: 70 } // Domaine 5 ‚â• 70
      }
    }
  }
};

/**
 * Mapping comp√©tence ‚Üí domaine
 */
export const COMPETENCY_TO_DOMAIN: Record<CompetencyId, DomainId> = {
  '1.1': 'D1', '1.2': 'D1', '1.3': 'D1',
  '2.1': 'D2', '2.2': 'D2', '2.3': 'D2',
  '3.1': 'D3', '3.2': 'D3', '3.3': 'D3',
  '4.1': 'D4', '4.2': 'D4', '4.3': 'D4',
  '5.1': 'D5', '5.2': 'D5', '5.3': 'D5', '5.4': 'D5', 
  '5.5': 'D5', '5.6': 'D5', '5.7': 'D5',
};

/**
 * Helper : obtenir l'ID du domaine pour une comp√©tence
 */
export function getDomainForCompetency(competencyId: CompetencyId): DomainId {
  return COMPETENCY_TO_DOMAIN[competencyId];
}

/**
 * Helper : obtenir toutes les comp√©tences d'un domaine
 */
export function getCompetenciesForDomain(domainId: DomainId): CompetencyId[] {
  return CEREDIS_CONFIG.domains[domainId].competencies;
}

/**
 * Helper : obtenir le nom d'un domaine
 */
export function getDomainName(domainId: DomainId): string {
  return CEREDIS_CONFIG.domains[domainId].name;
}
```

### Fichier 3 : `services/ceredis-calculator/engine/ceredisCalculator.ts` (30 min)

```typescript
import type { CeredisConfig, DomainId } from '../types';

/**
 * Calculer le score CEREDIS global (0-600)
 * 
 * Formule : Score = Œ£(Score_domaine √ó Poids_domaine) √ó 6
 * 
 * Le facteur 6 permet de passer d'une √©chelle 0-100 (domaines)
 * √† une √©chelle 0-600 (CEREDIS)
 * 
 * @param domainScores - Scores par domaine (0-100 chacun)
 * @param config - Configuration CEREDIS
 * @returns Score global (0-600)
 */
export function calculateCeredisScore(
  domainScores: Record<DomainId, number>,
  config: CeredisConfig
): number {
  let weightedSum = 0;
  let totalWeight = 0;

  // Calculer la somme pond√©r√©e
  for (const [domainId, score] of Object.entries(domainScores) as [DomainId, number][]) {
    const domainConfig = config.domains[domainId];
    
    if (!domainConfig) {
      console.warn(`[CEREDIS] Unknown domain: ${domainId}`);
      continue;
    }

    const weight = domainConfig.weight;
    weightedSum += score * weight;
    totalWeight += weight;
  }

  // S√©curit√© : si aucun poids, retourner 0
  if (totalWeight === 0) {
    console.warn('[CEREDIS] No domain weights found');
    return 0;
  }

  // Score moyen pond√©r√© (0-100)
  const averageScore = weightedSum / totalWeight;
  
  // Multiplier par 6 pour obtenir l'√©chelle 0-600
  const ceredisScore = averageScore * 6;

  // Arrondir √† 2 d√©cimales
  return Math.round(ceredisScore * 100) / 100;
}

/**
 * Valider qu'un score CEREDIS est dans les limites
 * 
 * @param score - Score √† valider
 * @param config - Configuration CEREDIS
 * @returns true si le score est valide
 */
export function validateCeredisScore(
  score: number,
  config: CeredisConfig
): boolean {
  return score >= config.scale.min && score <= config.scale.max;
}

/**
 * Normaliser un score dans les limites
 * 
 * @param score - Score √† normaliser
 * @param config - Configuration CEREDIS
 * @returns Score normalis√©
 */
export function normalizeCeredisScore(
  score: number,
  config: CeredisConfig
): number {
  const { min, max } = config.scale;
  
  if (score < min) return min;
  if (score > max) return max;
  
  return Math.round(score * 100) / 100;
}
```

---

## üéØ ORDRE DE D√âVELOPPEMENT (Suite - 4h30 restantes)

### 1. Continuer avec les 5 modules restants (2h30)

**Fichiers √† porter depuis JavaScript vers TypeScript** :

```bash
# Ouvrir ces fichiers en parall√®le :
# Source JS (r√©f√©rence)             | Destination TS (√† cr√©er)
/tmp/.../evidenceAggregator.js      ‚Üí services/ceredis-calculator/engine/evidenceAggregator.ts
/tmp/.../competencyCalculator.js    ‚Üí services/ceredis-calculator/engine/competencyCalculator.ts
/tmp/.../domainCalculator.js        ‚Üí services/ceredis-calculator/engine/domainCalculator.ts
/tmp/.../cecrlDecider.js            ‚Üí services/ceredis-calculator/engine/cecrlDecider.ts
/tmp/.../levelValidator.js          ‚Üí services/ceredis-calculator/engine/levelValidator.ts
```

**M√©thode pour chaque module** :
1. Ouvrir le fichier JS (source)
2. Comprendre la logique
3. R√©√©crire en TypeScript avec types stricts
4. Ajouter JSDoc commentaires
5. Tester mentalement la logique

### 2. Cr√©er le point d'entr√©e (30 min)

**Fichier** : `services/ceredis-calculator/index.ts`

```typescript
import type { Evidence, CeredisResult } from './types';
import { CEREDIS_CONFIG } from './config';
import { aggregateEvidences } from './engine/evidenceAggregator';
import { calculateCompetencyScores } from './engine/competencyCalculator';
import { calculateDomainScores } from './engine/domainCalculator';
import { calculateCeredisScore } from './engine/ceredisCalculator';
import { decideCecrlLevel } from './engine/cecrlDecider';
import { validateLevel } from './engine/levelValidator';

/**
 * Calculer le score CEREDIS pour un apprenant
 * 
 * Cette fonction orchestre tout le pipeline de calcul :
 * 1. Agr√©gation des preuves par comp√©tence
 * 2. Calcul des scores par comp√©tence
 * 3. Calcul des scores par domaine
 * 4. Calcul du score CEREDIS global
 * 5. D√©cision du niveau CECRL
 * 6. Validation des r√®gles strictes
 * 
 * @param userId - ID de l'utilisateur
 * @param evidences - Liste des preuves d'apprentissage
 * @returns R√©sultat complet du calcul CEREDIS
 */
export async function computeCeredisScore(
  userId: string,
  evidences: Evidence[]
): Promise<CeredisResult> {
  // 1. Agr√©ger les preuves par comp√©tence
  const aggregated = aggregateEvidences(evidences);

  // 2. Calculer scores par comp√©tence
  const competencyScores = calculateCompetencyScores(
    aggregated,
    CEREDIS_CONFIG
  );

  // 3. Calculer scores par domaine
  const domainScores = calculateDomainScores(
    competencyScores,
    CEREDIS_CONFIG
  );

  // 4. Calculer score CEREDIS global
  const ceredisScore = calculateCeredisScore(domainScores, CEREDIS_CONFIG);

  // 5. D√©cider du niveau CECRL
  const cecrlLevel = decideCecrlLevel(ceredisScore, CEREDIS_CONFIG);

  // 6. Valider avec r√®gles strictes
  const validation = validateLevel(
    cecrlLevel,
    ceredisScore,
    domainScores,
    evidences,
    CEREDIS_CONFIG
  );

  return {
    userId,
    ceredisScore,
    cecrlLevel: validation.level, // Niveau valid√© (peut √™tre d√©grad√©)
    domainScores,
    competencyScores,
    validation,
    computedAt: new Date().toISOString(),
    engineVersion: CEREDIS_CONFIG.version
  };
}

// Exporter aussi les fonctions individuelles pour les tests
export {
  aggregateEvidences,
  calculateCompetencyScores,
  calculateDomainScores,
  calculateCeredisScore,
  decideCecrlLevel,
  validateLevel
};
```

### 3. Cr√©er l'API Route (30 min)

**Fichier** : `app/api/ceredis/calculate/route.ts`

```typescript
import { NextRequest, NextResponse } from 'next/server';
import { computeCeredisScore } from '@/services/ceredis-calculator';
import PocketBase from 'pocketbase';
import type { Evidence } from '@/services/ceredis-calculator/types';

const pb = new PocketBase(process.env.NEXT_PUBLIC_POCKETBASE_URL);

/**
 * POST /api/ceredis/calculate
 * 
 * Calculer le score CEREDIS pour un utilisateur
 * 
 * Body: { userId: string }
 * 
 * Returns: CeredisResult
 */
export async function POST(request: NextRequest) {
  const startTime = Date.now();

  try {
    // 1. Parser la requ√™te
    const { userId } = await request.json();

    if (!userId || typeof userId !== 'string') {
      return NextResponse.json(
        { 
          success: false,
          error: { code: 'INVALID_USER_ID', message: 'userId is required' }
        },
        { status: 400 }
      );
    }

    // 2. R√©cup√©rer toutes les Evidences depuis PocketBase
    const records = await pb.collection('evidences').getFullList({
      filter: `user = "${userId}"`,
      sort: '-created',
      requestKey: null // D√©sactiver la d√©duplication
    });

    // 3. Mapper vers le format Evidence
    const evidences: Evidence[] = records.map(record => ({
      id: record.id,
      userId: record.user,
      competencyId: record.competency,
      type: record.type,
      score: record.score,
      timestamp: record.created,
      metadata: {
        activityId: record.activity,
        sessionId: record.session,
        duration: record.duration,
      }
    }));

    console.log(`[CEREDIS] Computing score for user ${userId} with ${evidences.length} evidences`);

    // 4. Calculer le score CEREDIS
    const result = await computeCeredisScore(userId, evidences);

    // 5. (Optionnel) Sauvegarder dans PostgreSQL
    // await saveCeredisResult(result);

    const processingTime = Date.now() - startTime;

    return NextResponse.json({
      success: true,
      result,
      stats: {
        totalEvidences: evidences.length,
        processingTime
      }
    });

  } catch (error) {
    console.error('[CEREDIS] Calculation error:', error);
    
    return NextResponse.json(
      {
        success: false,
        error: {
          code: 'CALCULATION_ERROR',
          message: error instanceof Error ? error.message : 'Unknown error'
        }
      },
      { status: 500 }
    );
  }
}

/**
 * GET /api/ceredis/calculate?userId=xxx
 * 
 * M√™me chose en GET pour faciliter les tests
 */
export async function GET(request: NextRequest) {
  const userId = request.nextUrl.searchParams.get('userId');
  
  if (!userId) {
    return NextResponse.json(
      { error: 'userId query parameter required' },
      { status: 400 }
    );
  }

  // R√©utiliser le handler POST
  return POST(
    new NextRequest(request.url, {
      method: 'POST',
      body: JSON.stringify({ userId })
    })
  );
}
```

### 4. Cr√©er le client frontend (30 min)

**Fichier** : `lib/ceredis/client.ts`

```typescript
import type { CeredisResult } from '@/services/ceredis-calculator/types';

/**
 * Calculer le score CEREDIS d'un utilisateur
 */
export async function calculateUserScore(userId: string): Promise<CeredisResult> {
  const response = await fetch('/api/ceredis/calculate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ userId })
  });

  if (!response.ok) {
    throw new Error(`Failed to calculate score: ${response.statusText}`);
  }

  const data = await response.json();
  
  if (!data.success) {
    throw new Error(data.error?.message || 'Calculation failed');
  }

  return data.result;
}
```

**Fichier** : `lib/ceredis/hooks.ts`

```typescript
'use client';

import { useQuery } from '@tanstack/react-query';
import { calculateUserScore } from './client';

/**
 * Hook pour r√©cup√©rer le score CEREDIS d'un utilisateur
 * 
 * @example
 * const { data, isLoading, error } = useCeredisScore(userId);
 */
export function useCeredisScore(userId: string) {
  return useQuery({
    queryKey: ['ceredis-score', userId],
    queryFn: () => calculateUserScore(userId),
    staleTime: 5 * 60 * 1000, // 5 minutes
    enabled: !!userId,
    retry: 1
  });
}
```

### 5. Tester (30 min)

```bash
# Compiler pour v√©rifier les erreurs
npm run type-check

# Si tout compile, tester l'API
curl -X POST http://localhost:3000/api/ceredis/calculate \
  -H "Content-Type: application/json" \
  -d '{"userId":"user-test-123"}'

# Ou avec un userId r√©el de votre PocketBase
curl -X POST http://localhost:3000/api/ceredis/calculate \
  -H "Content-Type: application/json" \
  -d '{"userId":"REAL_USER_ID"}'
```

---

## ‚úÖ CHECKLIST DE FIN DE JOURN√âE

√Ä la fin des 8 heures, vous devriez avoir :

- [ ] ‚úÖ Structure cr√©√©e (`services/ceredis-calculator/`)
- [ ] ‚úÖ Types d√©finis (`types.ts`)
- [ ] ‚úÖ Configuration cr√©√©e (`config.ts`)
- [ ] ‚úÖ 6 modules port√©s en TypeScript
- [ ] ‚úÖ Point d'entr√©e cr√©√© (`index.ts`)
- [ ] ‚úÖ API Route cr√©√©e (`/api/ceredis/calculate`)
- [ ] ‚úÖ Client frontend cr√©√© (`lib/ceredis/`)
- [ ] ‚úÖ Hook React cr√©√© (`useCeredisScore`)
- [ ] ‚úÖ Compilation OK (`npm run type-check`)
- [ ] ‚úÖ Test API r√©ussi (au moins 1 calcul)
- [ ] ‚úÖ Commit Git effectu√©

**Commit message sugg√©r√©** :
```bash
git add .
git commit -m "feat: integrate CEREDIS calculation engine

- Port 6 calculation modules from JavaScript to TypeScript
- Add comprehensive type definitions and configuration
- Create API route /api/ceredis/calculate
- Add React hooks for frontend integration
- Tests: Basic API call successful"

git push origin feature/ceredis-engine-integration
```

---

## üö® SI VOUS BLOQUEZ

### Probl√®me : Les modules JS sont difficiles √† comprendre

**Solution** : Ne pas tout porter en une fois
1. Commencer par `ceredisCalculator.ts` (d√©j√† fourni ci-dessus)
2. Continuer avec les plus simples en premier
3. Laisser les plus complexes pour la fin

### Probl√®me : Types TypeScript compliqu√©s

**Solution** : Les types sont d√©j√† fournis ci-dessus
- Copier-coller `types.ts` tel quel
- Copier-coller `config.ts` tel quel
- Adapter ensuite si besoin

### Probl√®me : Ne comprend pas la logique du moteur

**Solution** : Consulter le plan d√©taill√©
```bash
code /mnt/project/PLAN_INTEGRATION_MOTEUR_CEREDIS.md
```

Tout y est expliqu√© √©tape par √©tape avec des exemples.

### Probl√®me : L'API ne fonctionne pas

**Solutions possibles** :
1. V√©rifier les variables d'environnement
2. V√©rifier que PocketBase est accessible
3. V√©rifier qu'il y a des Evidences dans la DB
4. Regarder les logs : `npm run dev`
5. Tester avec un userId qui a des donn√©es

---

## üìû SUPPORT

Si vraiment bloqu√© apr√®s avoir essay√© les solutions ci-dessus :

1. **Documentation** : Relire `/mnt/project/PLAN_INTEGRATION_MOTEUR_CEREDIS.md`
2. **Code source** : Examiner l'archive extraite
3. **Types** : Tout est dans `types.ts` fourni ci-dessus
4. **Exemples** : Regarder les composants d√©j√† migr√©s

---

## üéØ OBJECTIF DE LA JOURN√âE

**√Ä la fin de la journ√©e** :
```typescript
// Ceci devrait fonctionner :
const result = await computeCeredisScore(userId, evidences);
console.log(result.ceredisScore); // 412.5
console.log(result.cecrlLevel);   // "B2"
```

**Et l'API devrait r√©pondre** :
```bash
POST /api/ceredis/calculate
Body: { "userId": "abc123" }

Response:
{
  "success": true,
  "result": {
    "ceredisScore": 412.5,
    "cecrlLevel": "B2",
    "domainScores": { ... },
    ...
  }
}
```

---

**Bonne chance ! üöÄ**

Le plus dur est de commencer. Une fois lanc√©, suivez le plan √©tape par √©tape.

**Temps estim√©** : 8 heures  
**Difficult√©** : Moyenne (code source disponible, types fournis)  
**Impact** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (D√©bloque tout le reste)
