Excellente Ã©tape.
Nous allons ajouter une **estimation empirique automatique du paramÃ¨tre dâ€™oubli Î»**, directement Ã  partir des donnÃ©es longitudinales issues de lâ€™instrumentation CEREDIS.

Lâ€™objectif est double :

* ğŸ”¬ Estimer Î» individuel (par apprenant et par niveau)
* ğŸ“Š Valider expÃ©rimentalement la cohÃ©rence du modÃ¨le exponentiel

Nous procÃ©dons rigoureusement.

---

# 1ï¸âƒ£ Rappel du modÃ¨le thÃ©orique

Nous avons posÃ© :

[
C_d(t) = \sum_i e^{-\lambda (t - t_i)}
]

Entre deux rÃ©activations, si aucune nouvelle validation :

[
C(t) = C(t_0) e^{-\lambda (t - t_0)}
]

Donc :

[
\ln C(t) = \ln C(t_0) - \lambda (t - t_0)
]

ğŸ‘‰ Relation linÃ©aire.

---

# 2ï¸âƒ£ MÃ©thode dâ€™estimation

## Transformation linÃ©aire

Posons :

[
y = \ln C(t)
]
[
x = t
]

Alors :

[
y = a - \lambda x
]

Donc :

> Î» = âˆ’ pente de la rÃ©gression linÃ©aire.

---

# 3ï¸âƒ£ Conditions expÃ©rimentales nÃ©cessaires

Pour estimer Î» :

* disposer de plusieurs mesures de ( C(t) ) sans nouvelle validation,
* isoler des segments â€œentre rÃ©activationsâ€,
* ignorer les points oÃ¹ C augmente (nouvelle validation).

---

# 4ï¸âƒ£ ImplÃ©mentation analytics-core

## ğŸ“¦ stability-estimator.ts

```ts
interface StabilityPoint {
  t: number;      // timestamp (days)
  value: number;  // weighted stability C(t)
}

export function estimateLambda(
  data: StabilityPoint[]
): number | null {

  if (data.length < 2) return null;

  const filtered = data.filter(p => p.value > 0);

  const x = filtered.map(p => p.t);
  const y = filtered.map(p => Math.log(p.value));

  const n = x.length;

  const sumX = x.reduce((a,b)=>a+b,0);
  const sumY = y.reduce((a,b)=>a+b,0);
  const sumXY = x.reduce((a,b,i)=>a + b*y[i],0);
  const sumX2 = x.reduce((a,b)=>a + b*b,0);

  const slope =
    (n*sumXY - sumX*sumY) /
    (n*sumX2 - sumX*sumX);

  const lambda = -slope;

  return lambda > 0 ? lambda : null;
}
```

---

# 5ï¸âƒ£ DÃ©tection automatique des segments exploitables

Ajouter :

```ts
export function extractDecaySegments(
  trajectory: StabilityPoint[]
): StabilityPoint[][] {

  const segments: StabilityPoint[][] = [];
  let current: StabilityPoint[] = [];

  for (let i = 1; i < trajectory.length; i++) {

    if (trajectory[i].value <= trajectory[i-1].value) {
      current.push(trajectory[i-1]);
    } else {
      if (current.length > 1)
        segments.push([...current]);
      current = [];
    }
  }

  if (current.length > 1)
    segments.push(current);

  return segments;
}
```

---

# 6ï¸âƒ£ Estimation robuste multi-segments

```ts
export function estimateLambdaFromTrajectory(
  trajectory: StabilityPoint[]
): number | null {

  const segments = extractDecaySegments(trajectory);

  const lambdas = segments
    .map(seg => estimateLambda(seg))
    .filter(l => l !== null) as number[];

  if (lambdas.length === 0) return null;

  return lambdas.reduce((a,b)=>a+b,0) / lambdas.length;
}
```

---

# 7ï¸âƒ£ Visualisation dans dashboard

Ajouter dans `StabilityCurve` :

* afficher Î» thÃ©orique
* afficher Î» empirique
* afficher RÂ² (qualitÃ© de fit)

---

# 8ï¸âƒ£ Calcul RÂ² (qualitÃ© dâ€™ajustement)

```ts
export function computeR2(
  data: StabilityPoint[],
  lambda: number
): number {

  const y = data.map(p => Math.log(p.value));
  const x = data.map(p => p.t);

  const meanY =
    y.reduce((a,b)=>a+b,0) / y.length;

  const ssTot =
    y.reduce((a,b)=>a + Math.pow(b-meanY,2),0);

  const ssRes =
    y.reduce((a,b,i)=> {
      const predicted =
        Math.log(data[0].value)
        - lambda*(x[i]-x[0]);
      return a + Math.pow(b - predicted,2);
    },0);

  return 1 - (ssRes/ssTot);
}
```

---

# 9ï¸âƒ£ RÃ©sultats analytiques possibles

Avec cette estimation tu peux :

* Estimer Î» par apprenant
* Estimer Î» par niveau CECRL
* Comparer Î» moyen cohorte
* Tester H0 : Î» constant vs variable
* Adapter Î» dynamiquement par individu

---

# ğŸ”Ÿ Extension avancÃ©e

On peut dÃ©finir :

[
\lambda_{eff} =
f(D_m, D_e, \text{fatigue}, \text{intervalle})
]

Et estimer un modÃ¨le mixte (effets fixes + alÃ©atoires).

---

# 11ï¸âƒ£ IntÃ©gration dans planification adaptative

Remplacer Î» statique par :

```ts
const lambda = estimateLambdaFromTrajectory(history)
             ?? defaultLambda;
```

Planification devient :

[
t^* = \frac{1}{\hat{\lambda}} \ln \frac{C}{\theta}
]

Donc :

> Spaced repetition personnalisÃ©e empiriquement.

---

# ğŸ”¬ Impact scientifique majeur

Tu passes de :

* modÃ¨le thÃ©orique fixÃ©

Ã  :

* modÃ¨le adaptatif estimÃ© empiriquement

Ce qui ouvre :

* validation expÃ©rimentale
* comparaison inter-individuelle
* publication en psychologie cognitive computationnelle

---

# ğŸš€ Prochaine Ã©tape stratÃ©gique

Deux directions puissantes :

1. ğŸ”¹ Ajouter estimation bayÃ©sienne robuste de Î»
2. ğŸ”¹ Construire Ã©tude comparative CEREDIS Î» empirique vs SM-2

Laquelle engages-tu ?
